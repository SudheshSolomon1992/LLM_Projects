{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94132b88-f207-4e47-8439-aca3dfa5055d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿Dorothy and the Wizard in Oz\n",
      "\n",
      "Author: L. Frank Baum\n",
      "\n",
      "Illustrator: John R. Neill\n",
      "\n",
      "Release date: September 10, 2007 [eBook #22566]\n",
      "\n",
      "Language: English\n",
      "\n",
      "Credits: Produced by Chris Curnow, Joseph Cooper, \n"
     ]
    }
   ],
   "source": [
    "with open ('wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "print (text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafb78a5-82c5-4fa1-a00a-29abb0cc2b3a",
   "metadata": {},
   "source": [
    "## Character Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "703fa1f5-7259-455b-82ce-f92f2b50d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sorted text of characters in the text\n",
    "chars = sorted(set(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f00a062b-6334-465b-91b1-e9f2075422b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63, 60, 67, 67, 70]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "string_to_int = {ch:i for i, ch in enumerate(chars)}\n",
    "int_to_string = {i:ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "encoded_hello = encode('hello')\n",
    "decoded_hello = decode(encode('hello'))\n",
    "\n",
    "print (encoded_hello)\n",
    "print (decoded_hello)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041294b8-da2b-4cac-8289-74e035dfdbe4",
   "metadata": {},
   "source": [
    "## Tensors instead of arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09b4461b-44f4-4adf-8388-0e1f02dfc194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4974f893-afb3-4304-ab9d-420da5b40d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([82, 30, 70, 73, 70, 75, 63, 80,  1, 56, 69, 59,  1, 75, 63, 60,  1, 49,\n",
      "        64, 81, 56, 73, 59,  1, 64, 69,  1, 41, 81,  0,  0, 27, 76, 75, 63, 70,\n",
      "        73, 24,  1, 38, 12,  1, 32, 73, 56, 69, 66,  1, 28, 56, 76, 68,  0,  0,\n",
      "        35, 67, 67, 76, 74, 75, 73, 56, 75, 70, 73, 24,  1, 36, 70, 63, 69,  1,\n",
      "        44, 12,  1, 40, 60, 64, 67, 67,  0,  0, 44, 60, 67, 60, 56, 74, 60,  1,\n",
      "        59, 56, 75, 60, 24,  1, 45, 60, 71, 75])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Users\\sudhe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\sudhe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\sudhe\\Documents\\Learning\\myLLM\\llm_env\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\sudhe\\Documents\\Learning\\myLLM\\llm_env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\sudhe\\Documents\\Learning\\myLLM\\llm_env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\sudhe\\Documents\\Learning\\myLLM\\llm_env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\sudhe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 638, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\sudhe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py\", line 1971, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\sudhe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\sudhe\\Documents\\Learning\\myLLM\\llm_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\sudhe\\Documents\\Learning\\myLLM\\llm_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\sudhe\\Documents\\Learning\\myLLM\\llm_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\sudhe\\Documents\\Learning\\myLLM\\llm_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\sudhe\\Documents\\Learning\\myLLM\\llm_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\sudhe\\Documents\\Learning\\myLLM\\llm_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\sudhe\\Documents\\Learning\\myLLM\\llm_env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\sudhe\\Documents\\Learning\\myLLM\\llm_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\sudhe\\Documents\\Learning\\myLLM\\llm_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\sudhe\\Documents\\Learning\\myLLM\\llm_env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\sudhe\\Documents\\Learning\\myLLM\\llm_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\sudhe\\Documents\\Learning\\myLLM\\llm_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\sudhe\\Documents\\Learning\\myLLM\\llm_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\sudhe\\AppData\\Local\\Temp\\ipykernel_12040\\4032919423.py\", line 1, in <module>\n",
      "    data = torch.tensor(encode(text), dtype=torch.long)\n",
      "C:\\Users\\sudhe\\AppData\\Local\\Temp\\ipykernel_12040\\4032919423.py:1: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  data = torch.tensor(encode(text), dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print (data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d74af7-f1a8-49f8-b925-11cccfebd734",
   "metadata": {},
   "source": [
    "## Train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f57e6257-38b2-4166-8798-8f1856c0e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e968dee6-9def-433f-9b20-e74b47f54e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([82]), target is 30\n",
      "When input is tensor([82, 30]), target is 70\n",
      "When input is tensor([82, 30, 70]), target is 73\n",
      "When input is tensor([82, 30, 70, 73]), target is 70\n",
      "When input is tensor([82, 30, 70, 73, 70]), target is 75\n",
      "When input is tensor([82, 30, 70, 73, 70, 75]), target is 63\n",
      "When input is tensor([82, 30, 70, 73, 70, 75, 63]), target is 80\n",
      "When input is tensor([82, 30, 70, 73, 70, 75, 63, 80]), target is 1\n"
     ]
    }
   ],
   "source": [
    "block_size = 8 # length of the sequence\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size + 1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print (f\"When input is {context}, target is {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce65a8-6ce2-4ea9-9c8c-df87ab7f6b8a",
   "metadata": {},
   "source": [
    "## Batch Size hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c8879-54b0-4373-8168-7999978610b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size # how many blocks are we using in paralell\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "# print(x.shape)\n",
    "print(x)\n",
    "print('targets:')\n",
    "print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
